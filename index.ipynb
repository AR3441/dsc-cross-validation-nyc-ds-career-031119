{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You learned about train-test-split before, but also noticed that running the model with a different split for train and test can lead to significantly different results. This is one of the many reasons why you'll want to consider cross-validation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem with train-test-split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using train-test-split, random samples of the data are created for the training and the test set. The problem with this is that the training and test MSE strongly depend on how the training and test sets were created. Let's see how this happens in practice using the auto-mpg data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's copy our pre-processed auto-mpg data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(\"auto-mpg.csv\") #reads in csv, and changes horsepower columns to string to int\n",
    "data['horsepower'].astype(str).astype(int)\n",
    "\n",
    "acc = data[\"acceleration\"]\n",
    "logdisp = np.log(data[\"displacement\"])\n",
    "loghorse = np.log(data[\"horsepower\"])\n",
    "logweight= np.log(data[\"weight\"])\n",
    "#uses numpy to get the log of the values in those columns of the dataframe\n",
    "\n",
    "scaled_acc = (acc-min(acc))/(max(acc)-min(acc))\t#min max scaling \n",
    "scaled_disp = (logdisp-np.mean(logdisp))/np.sqrt(np.var(logdisp))\n",
    "scaled_horse = (loghorse-np.mean(loghorse))/(max(loghorse)-min(loghorse))\n",
    "scaled_weight= (logweight-np.mean(logweight))/np.sqrt(np.var(logweight))\n",
    "#for disp, horse, and weight, standardization is being done , so you can compare scores before different types of variables\n",
    "\n",
    "\n",
    "data_fin = pd.DataFrame([])\n",
    "data_fin[\"acc\"]= scaled_acc\n",
    "data_fin[\"disp\"]= scaled_disp\n",
    "data_fin[\"horse\"] = scaled_horse\n",
    "data_fin[\"weight\"] = scaled_weight\n",
    "cyl_dummies = pd.get_dummies(data[\"cylinders\"], prefix=\"cyl\")\n",
    "yr_dummies = pd.get_dummies(data[\"model year\"], prefix=\"yr\")\n",
    "orig_dummies = pd.get_dummies(data[\"origin\"], prefix=\"orig\")\n",
    "mpg = data[\"mpg\"]\n",
    "data_fin = pd.concat([mpg, data_fin, cyl_dummies, yr_dummies, orig_dummies], axis=1)\n",
    "#new dataframe called data_fin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>acc</th>\n",
       "      <th>disp</th>\n",
       "      <th>horse</th>\n",
       "      <th>weight</th>\n",
       "      <th>cyl_3</th>\n",
       "      <th>cyl_4</th>\n",
       "      <th>cyl_5</th>\n",
       "      <th>cyl_6</th>\n",
       "      <th>cyl_8</th>\n",
       "      <th>...</th>\n",
       "      <th>yr_76</th>\n",
       "      <th>yr_77</th>\n",
       "      <th>yr_78</th>\n",
       "      <th>yr_79</th>\n",
       "      <th>yr_80</th>\n",
       "      <th>yr_81</th>\n",
       "      <th>yr_82</th>\n",
       "      <th>orig_1</th>\n",
       "      <th>orig_2</th>\n",
       "      <th>orig_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>1.125829</td>\n",
       "      <td>0.173727</td>\n",
       "      <td>0.720986</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>1.372223</td>\n",
       "      <td>0.321860</td>\n",
       "      <td>0.908047</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>1.191999</td>\n",
       "      <td>0.262641</td>\n",
       "      <td>0.651205</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>1.107370</td>\n",
       "      <td>0.262641</td>\n",
       "      <td>0.648095</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.148810</td>\n",
       "      <td>1.094964</td>\n",
       "      <td>0.219773</td>\n",
       "      <td>0.664652</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg       acc      disp     horse    weight  cyl_3  cyl_4  cyl_5  cyl_6  \\\n",
       "0  18.0  0.238095  1.125829  0.173727  0.720986      0      0      0      0   \n",
       "1  15.0  0.208333  1.372223  0.321860  0.908047      0      0      0      0   \n",
       "2  18.0  0.178571  1.191999  0.262641  0.651205      0      0      0      0   \n",
       "3  16.0  0.238095  1.107370  0.262641  0.648095      0      0      0      0   \n",
       "4  17.0  0.148810  1.094964  0.219773  0.664652      0      0      0      0   \n",
       "\n",
       "   cyl_8   ...    yr_76  yr_77  yr_78  yr_79  yr_80  yr_81  yr_82  orig_1  \\\n",
       "0      1   ...        0      0      0      0      0      0      0       1   \n",
       "1      1   ...        0      0      0      0      0      0      0       1   \n",
       "2      1   ...        0      0      0      0      0      0      0       1   \n",
       "3      1   ...        0      0      0      0      0      0      0       1   \n",
       "4      1   ...        0      0      0      0      0      0      0       1   \n",
       "\n",
       "   orig_2  orig_3  \n",
       "0       0       0  \n",
       "1       0       0  \n",
       "2       0       0  \n",
       "3       0       0  \n",
       "4       0       0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([mpg, scaled_acc, scaled_weight, orig_dummies], axis= 1)\n",
    "y = data[[\"mpg\"]]\n",
    "X = data.drop([\"mpg\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below repeats a train-test-split creation 20 times, using a test_size of 0.33. So what happens is, each time a new (random) train-test-split is created. See how training and testing MSEs swing around by just taking another sample!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num = 20\n",
    "train_err = []\n",
    "test_err = []\n",
    "for i in range(num):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "    linreg.fit(X_train, y_train)\n",
    "    y_hat_train = linreg.predict(X_train)\n",
    "    y_hat_test = linreg.predict(X_test)\n",
    "    train_err.append(mean_squared_error(y_train, y_hat_train))\n",
    "    test_err.append(mean_squared_error(y_test, y_hat_test))\n",
    "plt.scatter(list(range(num)), train_err, label='Training Error')\n",
    "plt.scatter(list(range(num)), test_err, label='Testing Error')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to deal with the issues that random sampling can introduce into interpreting the quality of our models, we'll use a more advanced technique called **K-Fold Cross Validation**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Fold Cross Validation expands on the idea of training and testing splits by splitting the entire dataset into {K} equal sections of data. We'll then iteratively train {K} linear regression models on the data, with each linear model using a different section of data as the testing set, and all other sections combined as the training set.\n",
    "\n",
    "We can then average the individual results frome each of these linear models to get a Cross-Validation MSE. This will be closer to the model's actual MSE, since \"noisy\" results that are higher than average will cancel out the \"noisy\" results that are lower than average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='cross-val-graphic.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can easily do this in scikit-learn using `cross_val_score`. If you want the mean squared error as an output, you need to specify `scoring` and pass \"neg_mean_squared_error\". Note that this negates your mean squared error, so larger means better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_5_results = np.mean(cross_val_score(linreg, X, y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "cv_10_results = np.mean(cross_val_score(linreg, X, y, cv=10, scoring=\"neg_mean_squared_error\"))\n",
    "cv_20_results = np.mean(cross_val_score(linreg, X, y, cv=20, scoring=\"neg_mean_squared_error\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-11.30081793,  -8.78320025, -23.69357412, -13.21110553,\n",
       "        -8.09324691, -36.70008362,  -7.54905107, -13.32088302,\n",
       "        -7.7893954 ,  -6.64032385,  -7.4894831 ,  -4.31665558,\n",
       "       -11.92488416,  -7.60371666,  -7.04479279, -32.31288826,\n",
       "       -82.75702561, -18.12473407, -23.17238559, -46.84727481])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(linreg, X, y, cv=20, scoring=\"neg_mean_squared_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to perform Cross-validations, and we strongly recommend you have a look at the [Cross-validation documentation in Scikit-Learn](http://scikit-learn.org/stable/modules/cross_validation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "Great! Now let's put this into practice on our Boston Housing Data!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
